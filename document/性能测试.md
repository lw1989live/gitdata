# 全栈性能测试修炼宝典JMeter实战（陈志勇）
# 目录
## 基础篇
## 第1章　性能方向职业发展　1
### 1．1　为什么选择软件测试　2
### 1．2　软件测试痛处　2
(1) 需求难以驾驭
(2) 岗位处在工作流末端
### 1．3　软件测试发展路线　3
我们可以暂且把软件测试职业路线分为3个方向，分别是业务路线、技术路线、管理路线；
4个象限，分别为执行层、中层、中高层过渡、高层。
（1）业务路线
　　常见业务路线的职位有QA经理、业务专家、产品经理、产品总监、行业咨询顾问等。
（2）技术路线
　　掌握编程技术，拥有业务经验，成为自动化测试工程师、性能测试工程师、软件开发工程师、安全测试工程师、系统分析师、测试总监、研发总监等。
（3）管理路线
　　积累业务知识或者提高技术储备，能够出色地完成本职工作，负责带领团队；岗位一般有测试leader、测试主管、测试经理及测试总监。

　执行层：
1 软件测试--功能（初级--专职过渡阶段）
2 软件测试--性能（专职）
3 软件测试--自动化（专职）
4 软件测试--安全（专职）
5 软件测试--白盒（专职）
6 软件测试--业务（专职）
7 软件测试--小组长、主管（管理路线）
8 软件开发（专职）
9 质量保证工程师SQA（专职--业务线）

　　中层：中级执行管理领导
1 测试分析师（专职--领导过渡阶段）
2 测试架构师初级（专职--领导过渡阶段）
3 测试经理（执行领导--管理路线）
4 QA经理（执行领导--技术路线）
5 产品经理（执行领导--业务线）
6 项目经理（执行领导--技术路线）
7 系统分析师
8 测试培训师

　　中高层过渡：
1 测试总监（执行领导--高级领导）
2 产品总监（业务路线）
3 行业咨询顾问（业务路线）
4 研发总监（技术路线）
5 项目总监（技术路线）

　　高层：
1 CQO--首席质量官
2 CTO--首席技术官
3 CIO--首席信息官
4 CEO--首席执行官
### 1．4　不仅仅是性能测试　4
软件测试还需要具备的能力
（1）需求
（2）代码
（3）运维
### 1．5　从招聘要求看岗位价值　5
### 1．6　性能测试技能树　8
职位技术要求
	测试工具
		Jmeter
		LoadRunner
	测试基础
		性能测试理论
		自动化测试理论
		测试开发
	服务器性能诊断
		CPU
		磁盘
		内存
		网络
	优化技能
		代码
		架构
		中间件
		操作系统
		数据库
			SQL
			配置
			设计
	协议
		HTTP/HTTPS
		WebSocket/Socket
		WebService
		其他RPC实现
	自动化
		接口自动化
		Web自动化
		移动App自动化
	持续集成
		Jenkins
		Maven/Ant
		Git/SVN
#### 1．6．1　测试工具　8
常见难点
1 用户和业务模型分析搭建
2 合适的脚本开发（大部分初学者不根据用户和业务模型来开发脚本，认为要回归成功即可）
3 合适的需求分析转化为场景设计（大部分初学者不知道如何根据需求进行场景设计）
4 大容量系统的数据生成和使用
5 大型系统的性能压力负载和实施
6 云计算的负载生成和实施
#### 1．6．2　测试基础　9
常见难点
1 评估需求
2 负载建模（用户与业务模型）
3 性能压力生成的原理和并发等之间的关系
4 性能测试用例
5 新系统需求分析
6 容量规划
7 性能测试策略
#### 1．6．3　代码　10
推荐使用java、python
#### 1．6．4　服务器性能诊断知识　10
1 Linux
2 windows server
3 oracle
4 mysql
5 Nosql--非关系型数据库
  1 键值数据库--redis
  2 列数据库--cassandra
  3 文档型数据库--mongoDB、couchdb

常见难点：
 1 进程、线程任务之间的区别？
 2 线程中断优先和原理
 3 进程的生命周期
 4 上下文切换
 5 I/O密集型和cpu密集型工作负载之间有什么区别？
 6 生产环境和测试环境之间换算？
 7 事务数据库和分析数据库的使用
 8 数据关系建模和设计
 9 TOP N SQL诊断和优化（执行路径、索引和表链接优化等）？
10 阻击和根治阻塞和死锁？
11 热点防范和定位优化
12 业务数据批量缓存化、异步化
13 数据库配置优化？
#### 1．6．5　性能调优技能　12
很多人说性能测试最难的就是定位性能瓶颈。
常见难点
1 系统硬件资源（CPU、网络、内存、IO）相互之间的关系及原理
2 选择可靠性能指标及指标之间的关联和判定方法
3 永不宕机的实现原理和常见错误
4 排队系统与延迟及缓存的优化关系
5 优化的成本和性价比
6 业务优化的操作实施
7 多系统串联原理及测试隔离
#### 1．6．6　自动化/持续集成　13
当下流行的持续集成工具：Jenkins、Git/SVN、Maven、Ant等；
#### 1．6．7　云计算及虚拟化　13
### 1．7　本章小结　13
## 第2章　性能测试初体验　14
	性能测试是一项综合性工作，致力于暴露性能问题，评估系统性能趋势。
### 2．1　性能测试的价值　15
软件测试分类
	测试方法
		白盒测试
		黑盒测试
		探索性测试
	程序运行状态
		静态测试
		动态测试
	软件阶段
		单元测试
		集成测试
		系统测试
		验收测试
		回归测试
		Alpha测试
		Beta测试
	服务类型
		B/S
		C/S
	测试内容
		功能测试
		负载测试 ○
		压力测试 ○
		性能测试 ○
		大数据测试 ○
		易用性测试
		安装测试
		恢复测试 ○
		安全性测试
		兼容性测试
		内存泄漏测试 ○
		竞品测试 ○
		可靠性测试 ○
		文档测试
	服务类型
		手机端测试
		PC端测试

　从图中可以看出，性能测试在整个软件测试环节中占了50%的内容，比如负载测试、压力测试、性能测试、大数据量测试、恢复测试、内容泄露测试、竞品测试（比较测试）和可靠性测试。
### 2．2　性能测试流程　17
性能测试常规流程图
Start
	↓
学习业务	→	分析需求									END
			↓											↑
设计模型	←	工作评估									编写报告汇报工作
	↓			 										↑Y
┌→编写计划			↓─	─	─	┐N			系统调优	←N	准出检查
N	↓	  ┌→	开发脚本		─┐	│				↓			↑
└	评审	─Y├→	准备测试环境	←┼→	Check	Y→	执行测试	→	分析性能汇报工作
		  └→	准备测试数据	─┘	│				↓
					↑─	─	─	┘N			管理缺陷

（1）业务学习：通过查看文档，手动操作系统来来了解系统性能；
（2）需求分析：分析系统非功能需求，圈定性能测试的范围，了解系统的性能指标；
（3）工作评估：工作量分解，评估工作量，计划资源投入（即需要多少人力，多少工作日来完成性能测试工作）；
（4）设计模型：圈定性能测试范围后，把业务模型映射成测试模型；
（5）计划编写：计划测试工作，在文档中明确列出测试范围、人力投入、持续时间、工作内容、风险评估、风险应对策略等
（6）脚本开发：录制或者编写性能测试脚本，开发测试挡板程序，开发测试程序等；
（7）测试环境准备：性能测试环境准备包括服务器与负载机两部分，服务器是被测系统的运行平台，负载机是我们用来生产负载的机器，用来安装负载工具，运行测试脚本；
（8）测试数据准备：根据测试模型来准备被测系统的主数据与业务数据；
（9）测试执行
（10）缺陷管理：对性能测试过程中发现的缺陷进行管理；
（11）性能分析：对性能测试过程中暴露出来的问题进行分析，找出原因；
（12）性能调优：性能测试人员与开发人员一起来解决性能问题；
（13）测试报告：测试工作的重要交付文件，对测试结果进行报告，主要包括性能指标说明（tps、rt、cpu等）；
	性能测试主要交付件：
	1 测试计划
	2 测试脚本
	3 测试程序
	4 测试报告或者阶段性测试报告
（14）评审：对性能报告中的内容进行评审，确认问题，评估上线风险。
### 2．3　性能测试成功与失败要素　18
性能测试有几大难点：
(1)需求分析
　　对性能测试进行需求分析，通常情况下测试人员会直接依赖需求人员或者项目经理的口述或者有缺陷的文档。实际上，大多数情况下我们测试人员需要自己来引导相关的运维人员和需求人员给出具体的需求数据，并对这些数据进行二次分析，得出我们真实的性能需求。
　　对于初次上线的系统，我们需要使用同行的系统数据，进行用户行为分析和商业数据结构的估算为前提，利用性能估算法推算。得到的负荷和响应时间数据可以被应用于验证所计划的模型的能力，并帮助做出对策。
　　对于已经上线的系统，我们可以通过运维人员获取TPS和时间的比例分布图、用户数和时间的分布图、数据库ER关系图、容量数据等，直接精确得出目前系统的用户行为和业务数据关系，进而得出我们需要的性能需求。
(2)场景设计
(3)性能诊断调优
(4)环境搭建和模拟

重点关注点：
1 评估系统，需求分析
2 场景设计、用例设计
3 测试执行、是否通过
	判断是否通过测试关注点
		响应时间(RT)
		吞吐量(TPS)
		事务成功率
		硬件指标
			CPU
			内存
			存储
			网络
		稳定性
		内存有无泄漏
		其它
			数据库
			中间件
			缓存
			JVM
4 性能诊断优化
### 2．4　不同角色看性能　20
技术部门一般有下面几种角色：开发、测试、架构师、运维人员、（系统管理员、DBA）
（1）黑盒测试的角度
　　黑盒测试只关心应用程序的单步响应时间，性能好坏就看应用时间多少，也就是数据流经过服务器、服务器集群经过网络传输后往返的时间总和。
（2）开发角度
	1 架构合理性
	2 数据库设计合理性
	3 代码
	4 系统内存的使用方式
	5 系统线程使用方式
	6 系统资源是否有恶性，不合理竞争
（3）系统管理员角度
	1 硬件资源利用率
	2 JVM
	3 DB
	4 系统是否支持7*24的服务
	5 扩展性，兼容性，最大容量，可能的瓶颈
（4）性能测试的角度
	1 服务器硬件的性能
	2 根据需求和历史数据制定性能目标
	3 建立性能通过模型
	4 对开发代码框架和硬件框架进行性能分析
	5 针对开发发布版本的基准测试
	6 执行软件性能验收及稳定性测试
	7 生产环境的配置及优化
	8 制定性能测试的测试用例
	9 制定性能测试的场景设计
	10 协调各部门配合
	11 特定的性能分析

### 2．5　性能测试工具选择　21
### 2．6　性能测试相关术语　22
（1）负载：模拟业务操作对服务器造成压力的过程，比如模拟100个用户进行发帖。
（2）性能测试（Performance Testing）：模拟用户负载来测试系统在负载情况下，系统的响应时间，吞吐量等指标是否满足性能需求。
（3）负载测试（load Testing）：在一定软硬件环境下，通过不断加大负载（不同虚拟用户数）来确定在满足性能指标情况下能够承受的最大用户数。这些性能指标包括：TPS（每秒事务数）、RT（事务平均响应时间）、CPU using（CPU利用率）、MEM using（内存使用率）等软硬件指标。
（4）配置测试（Configuration Testing）：为了合理地调配资源，提高系统运行效率，通过测试手段来获取、验证、调整配置信息的过程。
（5）压力测试\强度测试（Stress Testing）：在一定软硬件环境下，通过高负载的手段来使服务器资源处于极限状态，测试系统在极限状态下长时间运行是否稳定，确定是否稳定的指示包括TPS、RT、CPU using、MEM using等。
（6）稳定性测试（Endurance Testing）：在一定软硬件环境下，长时间运行一定负载，确定系统在满足性能指标的前提下是否运行稳定。一般我们会在满足性能要求的负载情况下加大1.5倍-2倍的负载量进行测试。
（7）TPS：每秒完成的事务数，通常指每秒成功的事务数，性能测试中重要的综合性性能指标。一个事务是一个业务度量单位，有时一个事务会包括多个子操作，为了统计方便，会把着多个子操作记为一个事务。
（8）RT/ART（Response Time\average response time）:响应时间/平均响应时间，指一个事务花费多长时间完成，一般取平均响应时间。
（9）PV（page view）：每秒用户访问页面的次数，此参数用来分析平均每秒有多少用户访问页面。
（10）Vuser虚拟用户（Virtual user）：模拟真实业务逻辑步骤的虚拟用户，虚拟用户模拟的操作步骤都被记录在虚拟用户脚本里。Vuser脚本用语描述Vuser在场景中执行的操作。
（11）Concurrency并发，并发分为狭义和广义两类。狭义的并发，即所有用户在同一时刻作品同一件事情或者操作，或者所有用户进行完全一样的操作；广义的并发，即多个用户对系统发出了请求或进行了操作，但是这些请求或操作可以是不同的。
（12）场景（Scenario）：性能测试过程中为了模拟真实用户的业务处理过程，在loadrunner中构建的基于事务、脚本、虚拟用户、运行设置、运行计划、监控、分析等一系列动作的集合，称之为性能测试场景。场景中包含了待执行脚本、脚本组、并发用户数、负载生成器、测试目标、测试执行时的配置条件等。
（13）思考时间（Think Time）：模拟真实用户在实际操作时的停顿间隔时间。也就是说，用户在进行操作时，每个请求之间的间隔时间。
（14）标准差（Std. Deviation）：标准差越小，说明波动越小，系统越稳定。
### 2．7　性能测试通过标准　23
Web项目性能测试通过标准
┏━					┳			┳					┳				┳		┓
┃类别				┃判断维度		┃不通过				┃通过			┃备注	┃
┡					╀			╀					╀				╀──────	┩
│通用互联网服务端性能	├超时概率		┼大于 0.5‰			┼小于0.5‰		┼
│					├错误概率		┼大于 0.5‰			┼小于0.5‰		┤────────	┤
│					├TPS 		┼小于期望高峰值		┼大于期望高峰值	┤			│
│					├CPU利用率 	┼大于75%				┼小于75%			┤			│
│					├响应时间		┼大于期望时间			┼小于期望高峰值	┤			│
│					├Load 		┼平均每核CPU的Load大于1┼平均每核CPU的Load小于1┤		│
│					├JVM内存使用率┼大于80%				┼小于80%			┤			│
├──────────────────	├Full GC频率	┼平均小于半小时1次		┼平均大于半小时1次	┼			│
│前端页面性能			┼YSlow评定	┼YSlow评定为C级以下	┼	YSlow评定为C级，或C级以上	┤
└─					┴			┴					┴							┴
### 2．8　性能测试趋势　24
### 2．9　本章小节　24
性能测试工作是一个综合学科：对技术要求高、广，也要求具备一定沟通能力。
性能测试的工作过程中要注意的关键点也比较多，首先要做好性能需求分析，不充足的性能需求分析直接导致性能测试工具失败。接着要做好用例及场景设计，尽可能复现实际负载，这样的执行工作才是可信赖的，可参考的。执行过程要做好性能监控工作，为问题分析提供数据支撑。
## 工具篇
## 第3章　JMeter体系结构　25
### 3．1　JMeter简介　26
### 3．2　JMeter体系结构　26
1 元件：JMeter工具菜单中的一个子菜单，比如HTTP请求、事务控制器、响应断言就是一个元件。
2 组件：一组元件的集合，比如逻辑控制器中有事务控制器

			Y1				Y2	Z
X1			取样器				断言	监听器
X2	前置处理器	配置元件	后置处理器
X3			控制器
X4			定时器
X5		线程组
说明：

X空间有5个维度，Y 空间分为2个维度，Z空间1个维度；
X1 ~ X5是负载模拟的一个过程，使用这些组件来完成负载的模拟；
Y1：包含的是负载模拟部分，负责模拟用户请求；
Y2：结果验证部分，负责验证结果正确性；
Z：负载结果收集，实践上只有一个组成部分 —— 监听器，监听器不仅可以放在线程组之内，也可以放在线程组之外；
JMeter基本原理是建立一个线程池，多线程运行取样器产生大量负载，在运行过程中通过断言来验证结果的正确性，通过监听器来记录测试结果。参数可以X2中的配置元件或者前置处理器来完成；如果有关联需求，可以通过后置处理器来完成；模拟多少用户，运行多长时间就可以利用定时器来设置；如果我们想要控制业务的执行逻辑，比如登录只运行一次，就可以使用控制器来完成；

#### 3．2．1　X1【取样器】　27
用来模拟用户操作，向服务器（被测试系统）发出http请求、WebService（SOAP/XML-RPC Request）请求或者Java请求等。我们可以把Http请求元件看成是一个没有界面的浏览器，可以发送请求也可以接收请求数据；
#### 3．2．2　X1【断言】　28
断言用来验证结果是否正确，LoadRunner中的检查点就是JMeter中的断言。
断言：用一个预设的结果（值、表达式、时间长短等条件）与实际结果匹配，匹配到则成功，反之失败；
#### 3．2．3　X1【监听器】　28
JMeter的测试结果需要添加监听器来收集，JMeter结果收集程序的设计模式就是监听器模式。JMeter的监听器有两个任务；
（1）添加结果监听，并且可以保存测试结果到文件，这些结果数据可以供两次分析使用。
（2）展示结果；可以以表格及图形的形式展示结果，方便测试人员分析测试结果。我们在开发测试脚本时，不可避免需要调试，监听器也提供了辅助（比如查看结果树，我们可以在其中看到请求与响应的数据）。
【取样器】、【断言】、【监听器】组合在一起就可以帮助我们完成发送请求、验证结果以及记录结果三项工作；
#### 3．2．4　X2【前置处理器】　29
在测试脚本开发过程中，我们在请求发送前可能会做一些环境或者参数的准备，那么我们可以在前置处理器中来完成这些工作。
#### 3．2．5　X2【配置元件】　29
性能测试中为了模拟大量用户操作，我们需要参数化，Jmeter的参数化可以通过配置元件来完成，它可以帮助我们从文件中读取测试数据。
配置元件可以为取样器提供预备数据，然后由取样器发出请求。
#### 3．2．6　X2【后置处理器】　30
后置处理器一般放在取样器之后，用来处理服务器的返回结果，
比如一个Web应用程序，我们登陆后会返回一个SessionID，我们利用模拟器请求时就需要带上这个属性，由服务器返回，可以通过正则表达式来获取。
后置处理器就是专门用来对数据做处理的元件。
 【前置处理器】、【配置元件】、【后置处理器】都是为取样器提供数据支持的，取样器关注的是业务逻辑
#### 3．2．7　X3【控制器】　31
拿收邮件为例，只需要登录一次就可以查看多份邮件，如何控制登陆次数？可以参考JMeter中的逻辑控制器（后续说的控制器）。
#### 3．2．8　X4【定时器】　31
为了足够真实地模拟用户负载，我们有时会需要模拟一些请求在同一时刻发出去，就好像把大家集合在一条起跑线上，听指令，一声令响，同时起跑。结合的功能就可以由定时器来完成
#### 3．2．9　X5【线程组】　31
线程组用于模拟大量用户负载的情况，在此元件中可以设置运行的线程数（就是模拟多少用户，一用户一线程），其设置也较简单，除了设置线程数之外，还可以设置线程时长，定时运行。
#### 3．2．10　Test Fragment　32
JMeter GUI菜单中可以看到Test Fragment 这个组件，它是一个辅助组件，它可以放置任何JMeter测试元件，它存在的理由：
（1）在脚本开发过程中可以用来备份元件；
（2）TestFragment 下的元件可以被模块化控制器调用，可以利用它来模块化请求，供模块控制器调用；
#### 3．2．11　工作台　32
工作平台不直接参加运行，有间接作用。功能有：
（1）运行JMeter录制Http协议时就用到它，建立一个HTTP代理服务器元件，设置代理信息然后进行录制；
（2）设置服务器监控（HTTP Mirror Server），不建议使用此功能来做测试监控，出于对Jmeter负载产生影响去考虑；
（3）显示当前JMeter属性信息；
（4）备份脚本；
JMeter的设计理念也是采用大多数性能测试工具的方式开发，方便进行扩展。
### 3．3　JMeter运行原理　33
JMeter是通过线程的方式来运行的，它运行在JVM上，因为通过进程的方式每个进程的开销比较大，每台负载机上的进程数量就不会允许太多，当需要大量负载机时，就不经济了。再者java支持多线程。它通过线程组来驱动多线程发起负载，jmeter的运行场景不仅仅是GUI，还有命令行，命令行对于负载机的资源消耗会更小；

（1）控制机：运用多台JMeter负载机进行性能测试时，被选中作为管理机的那台机器即是控制机；
（2）负载机：向被测试应用服务器发起负载的机器，控制机同时也是一台负载机；
（3）流程运行逻辑：
	远程负载机首先启动Agent程序(Agent:jmeter-server.bat)，待控制机连接；
	控制机连接上远程负载机；
	控制机发送指令（脚本及启动命令）启动线程；
	负载机运行脚本，回传状态（包括测试结果）；
	控制机收集结果并显示；
### 3．4　JMeter测试计划要素　34
JMeter中一个脚本即是一个测试计划，也是一个管理单元。JMeter的请求模拟与并发数（设置线程数，一个线程代表一个虚拟用户）设置都在脚本文件中一起设置，测试计划要素如下：
（一）脚本中测试计划只能有一个
（二）测试计划中至少要有一个线程组
（三）至少要有一个取样器
测试的目的就是模拟用户请求，没有取样脚本就毫无意义，没有意义就不用谈论对错了。
（四）至少要有一个监听器
测试结果用来衡量系统性能，我们需要从结果中分析系统性能。
### 3．5　JMeter环境介绍　35
可以安装至windows或者linux系统上

1、安装
2、JMeter工具目录介绍
bin：放置各类配置文件（比如日志文件、JVM设置等）、启动文件（JMeter启动快捷方式，报告生成快捷方式、、Heap Dump快捷方式等 ）、启动jar包、示例脚本等；
docs：放置jmeter API离线帮助文档，Web方式；
extras：JMeter辅助功能，提供与Ant、Jenkins集成的可能性，我们可以利用Ant与Jenkins来构建性能测试自动化框架。Ant可以利用xsl脚本把XML格式的测试结果以HTML方式展示，
lib：JMeter组件以jar包的形式放置在lib/ext目录下，如果扩展JMeter组件，扩展后的jar包即放在此目录下，如图3-20所示，JMeter启动时会加载此目录下的jar包；
license：JMeter licenses相关声明信息放在此文件夹，全部是文本文件，对测试没有实际意义；
printable_docs：JMeter的离线帮助文件放置目录，是我们学习它的向导；
LICENSE：License说明文件；
NOTICE：版权声明；
README：jmeter简明介绍；
3、环境变量
4、启动
### 3．6　JMeter与LoadRunner异同　37
1、两者的异同
（1）LoadRunner是性能测试的领袖，标准制定者；JMeter是后起之秀；
（2）LoadRunner主要是由C语言，支持Java、VB、C#；JMeter是纯Java开发，支持多种Java脚本语言；
（3）LoadRunner费用高昂，JMeter完全免费；LoadRunner学习成本更低；
（4）LoadRunner支持多种应用的性能测试，不管C、Java、VB、JavaScript、C#开发的程序、数据库、本地程序也好、远程调用也好；C/S还是B/S模式甚至移动端都可以不负使命来完成。JMeter虽然功能有限，不过还是可以通过编程来扩展。所以大家不要将扩展想的那么难，解决问题应该是我们的追求，这正是技术价值的体现，也是作为一个性能测试工程师的核心价值；
（5）LoadRunner的结果分析器十分强大，JMeter在第三方插件的扩展下也具备了与LoadRunner相媲美的体验；
（6）工具没有好坏，更在于使用的人，对于企业来讲，可靠、低成本地解决性能问题才是硬道理；
### 3．7　本章小结　38
本章我们框架性介绍了JMeter的组成及运行原理，实际上它与多数的性能测试工具原理相似。运行逻辑主要是下面3部分。
	第一，利用取样器模拟用户请求;如果需要做一些数据及环境的准备，那么就使用配置管理器；如果需要对响应的数据做处理，使用后置处理器。
	第二，控制运行；使用线程组来设置运行场景，利用逻辑控制器来控制业务。
	第三，收集结果，利用断言古验证测试结果，利用监听器来收集显示测试结果。
同时JMeter也支持远程运行，弥补单台机器负载不够的情况。远程运行时远程负载机要运行Agent(jmeter-server.bat来启动).
## 第4章　JMeter脚本开发　39
### 4．1　JMeter工作区介绍　40
各个分区介绍：
1、区域1是一个目录树，存放测试设计过程中使用到的元件；执行过程中默认从根节点顺序遍历树上的元件。工作台也可以用来存放元件，元件不会被执行，可以备份；
元件：例如我们要向服务器发送一个Http Post请求，这个请求是由一个HTTP请求取样器来完成的，叫做“HTTP请求”的取样器就是元件。在1区域添加进来的都是元件；
2、区域2是测试计划编辑区域，在【用户定义变量】区域我们可以定义整个测试计划共用的全局变量，这些变量对多个线程组有效，还可以添加测试计划依赖的jar包，比如JDBC方式连接数据库的驱动；
3、区域3是菜单栏，图标是快捷键方式，从左到右依次是：

### 4．2　JMeter Http协议录制　41
#### 4．2．1　Badboy进行录制　41
Badboy是一个浏览器模拟工具，具有录制及回放功能，还可以进行测试。可以用它来做自动化测试，因为它有捕获表单数据的功能。我们可以用它来对Web页面进行诊断，诊断系统响应快慢，响应数据大小。
Badboy录制的脚本可以直接导至成.jmx格式，此后缀正是JMeter脚本保存的格式，jmx实际上是一个XML格式的文件。
Badboy有两种录制方式：Request方式与Navigation方式。以下对Badboy的录制方式的区别仅进行介绍
	1、request：模仿浏览器发送表单信息到服务器，每一个资源都将作为请求发送；
	2、Navigation：记录用户鼠标动作，类似于著名的自动化测试工具QTP，回放时模拟一个点击；
基于JMeter脚本要求，我们需要选用request方式来进行录制，这些请求将会以jmx的格式保存下来，从而我们才可以导入JMeter中复用。

打开Bayboy,初始界面默认开启Request的录制模式。
Script目录树结构介绍：
	Test Suite 1：默认的脚本根节点，类似JMeter的测试计划根节点。
	Test1：测试活动根节点，可理解为一个业务功能脚本存放在此目录下。
	Step2：测试活动的步骤，如果一个业务过程比较长，可分为多个测试步骤。

开始录制：
Step1：进入网址。
打开录制按钮（默认打开），输入网址，点击 -> 或回车，即开始录制。
Step2：点击登录，输入用户名及密码，验证成功后进入微博首页。
1.点击点击新建一个Step2
2.再点击登录进行登录操作。
Step3：在微博首页，发布微博。
1.先点击新建一个Step3
2.在输入框内编辑微博内容，点击发布。
这样，我们已经录制完了登录及发微博的全过程。

录制完成后导出成JMeter脚本，路径：【File】-【Export to JMeter】-【选择保存路径】
在JMeter中打开已录制好的脚本。路径：【File】-【Open】-【打开保存路径】-【选择脚本文件】
JMeter以树形结构显示脚本，执行时原则上按节点先后顺序往下执行。
Test Plan: 测试计划，JMeter测试脚本根节点。每个测试脚本都是一个测试计划。

User Defined Variables：设置用户全局变量。
Run Thread Groups consecutively：独立运行每个线程组，不设置时多个线程组同时运行。
Run tearDown Thread Groups after shundown of main threads：关闭主线程后运行treardown程序来正常关闭线程组。
Function Test Mode：函数测试模式。
Add Directory or jar to classpath：把测试需求依赖的jar包或包所在的目录加入类路径。
Thread Group：模拟虚拟用户的发起点，再次可以设置线程数及于运行次数或者运行时间，还可以定义调度时间与运行时长。



录制为脚本以后的动作
1、介绍脚本中的各个元件：
（1）设置用户全局变量，即在“用户定义的变量”中定义；
（2）独立进行每个线程组：如果一个测试计划中有多个线程组，设置此项可以生效。不设置时每个线程组同时运行；
（3）Run teardown Thread Group，关闭主线程后运行teardown程序来正常关闭线程组（运行的线程本次迭代完成后关闭）；
（4）函数测试模式：在调试脚本的过程中我们可能需要获取服务器返回详细信息就可以选择此项，此项记录较多的数据会影响测试效率，所以在执行性能测试时请关闭此项；
（5）Add directory or jar to classpath，把测试需要依赖的jar包或包所在的目录加入类路径，建议大家放在jmeter/lib目录底下；
2、ThreadGroup：线程组，模拟虚拟用户的发起点，在此可以设置线程数及运行次数或者运行时长，还可以定义调度时间与运行时长；
3、HTTP Cookie Manager：我们知道IE访问Web页面时会记录Cookie信息，JMeter通过加入HTTP Cookie Manager来自动记录Cookie信息，JMeter通过加入HTTP Cookie Manager来自动记录Cookie信息；
（1）JMeter支持的Cookie标准有多种，同时，JMeter也提供了两组程序实现来支持这些Cookie标准，分别是HttpClient3与HttpClient4。可以将他们看成一个没有界面的浏览器，用它来完成浏览器的各种动作。
4、以下是Cookie标准，HttpClient3.1可以支持：
	RFC2109、RFC2965、Netscape标准、Browser Compatibility、Ingore  Cookie
5、User Defined Variable：用户自定义的变量，在此我们可以定义后面元件需要引用的变量并对其进行赋值。jsessionid一般是服务器返回的，每个用户返回的都不一样，所以在此不应该固定这个值，但是Badboy转换的脚本把jsessionid放到了此元件中，所以我们要把它除掉； 
6、Http Header Manager：管理HTTP头信息，我们可以从中找到诸如User-Agent、Connection、content-type、Accpect、Cookie、location302重定向地址等信息；
7、Step1：实际上这是一个循环控制器，我们可以在【逻辑控制器】中找到它。在此我们可以设置循环次数，以我们录制业务为例，一次登录可以多次发送新贴，所以把登录Step1的循环次数设置为1，Step2/3进入板块与发帖的循环次数设置为永远。
8、一个网址就是一个HTTP请求元件，可以在【Sampler】中找到它的身影。
9、属性介绍：
（1）Web服务器：指定Http请求的主机地址，不需要加上“http://”，JMeter 自动加上，普通Web服务端口默认是80，邮箱端口一般是443，126邮箱也用此端口；如果访问地址中带有其他端口号应该在对应的位置填上；
（2）Tmieouts：指定超时时间，单位是毫秒；Connect指定连接超时时间，Response指定响应超时时间；
（3）Implementation：下拉列表有3个选择项，其中HttpClient是Apache Jakarta Common下的子项目，通过它可以高效地访问HTTP协议的资源，我们可以把它看成是一个没有界面的浏览器。建议使用HttpClient4；
（4）协议：我们录制的论坛登录用的是http协议，所以在此要填入http。https是SSL的连接；
（5）方法：下拉列表中有八个选项，其中我们常用的是Post提交请求对于表单理论上没有长度限制，用户一般也看不到提交的内容，较get方式安全；
（6）Content encoding：字符编码格式，默认iso8859，不确定时可以向开发团队确认，不妨试一下UTF-8，大多数应用都会指定成UTF-8格式；
（7）路径：除去主机地址部分的访问链接，这是/entry/cgi/ntesdoor;
（8）自动重定向：HttpClient接收到请求后，如果请求中包含重定向请求，HttpClient是可以自动跳转的，但是只针对Get与Head请求，勾选此项则“跟随重定向”失效；
（9）跟随重定向：Http Request取样器是默认选项，当响应Code是3xx是，自动跳转到目标地址。JMeter与自动重定向不同，会记录重定向过程中的所有请求响应，在查看结果树时可以看到服务器返回的内容，可以对响应的内容做关联；

#### 4．2．2　JMeter配置代理进行录制　49
### 4．3　JMeter 脚本调试　52
### 4．4　JMeter 关联　55
#### 4．4．1　后置处理器　56
#### 4．4．2　Regular Expression Extractor　56
### 4．5　JMeter 参数化　60
#### 4．5．1　配置元件　60
#### 4．5．2　CSV Data Set Config　60
#### 4．5．3　函数助手　62
#### 4．5．4　访问地址参数化　64
#### 4．5．5　HTTP请求默认值　64
### 4．6　JMeter 检查点　65
#### 4．6．1　断言　65
#### 4．6．2　Response Assertion　66
### 4．7　JMeter事务　68
#### 4．7．1　逻辑控制器　68
#### 4．7．2　事务控制器　68
### 4．8　JMeter 集合点　69
#### 4．8．1　定时器　69
#### 4．8．2　同步定时器　69
### 4．9　JMeter元件运行顺序　70
### 4．10　本章小结　72
## 第5章　JMeter负载与监听　74
### 5．1　场景设计　75
### 5．3　场景运行　77
#### 5．3．1　GUI运行　77
#### 5．3．2　非GUI运行测试　79
### 5．4　性能参数配置　82
### 5．5　测试监听　83
#### 5．5．1　JMeter监听器　83
#### 5．5．2　开源监听插件　85
### 5．6　本章小结　85
## 第6章　JMeter元件详解　86
### 6．1　逻辑控制器　87
#### 6．1．1　ForEach Controller（循环控制器）　87
#### 6．1．2　Simple Controller　89
#### 6．1．3　Include Controller　90
#### 6．1．4　Runtime Controller　90
#### 6．1．5　Switch Controller　91
#### 6．1．6　While Controller　91
#### 6．1．7　Interleave Controller　91
#### 6．1．8　Once Only Controller　92
#### 6．1．9　Throughput Controller　93
#### 6．1．10　If Controller　94
#### 6．1．11　Module Controller　94
#### 6．1．12　Random Controller　95
#### 6．1．13　Random Order Controller　95
#### 6．1．14　Loop Controller　96
#### 6．1．15　Recording Controller　96
#### 6．1．16　Transaction Controller　97
### 6．2　配置元件　98
#### 6．2．1　FTP请求默认值　98
#### 6．2．2　HTTP Authorization Manager　99
#### 6．2．3　HTTP Request Defaults　99
#### 6．2．4　Java Request Defaults　99
#### 6．2．5　JDBC Connection Configuration　100
#### 6．2．6　Random Variable　100
#### 6．2．7　Counter　100
#### 6．2．8　Login Config Element　101
### 6．3　定时器　101
#### 6．3．1　Gaussian Random Timer　102
#### 6．3．2　Constant Timer　102
#### 6．3．3　Synchronizing Timer　102
#### 6．3．4　Constant Throughput Timer　102
#### 6．3．5　Uniform Random Timer　103
#### 6．3．6　Poisson Random Timer　103
#### 6．3．7　BeanShell Timer　103
#### 6．3．8　BSF Timer　106
#### 6．3．9　JSR223 Timer　106
### 6．4　前置处理器　106
#### 6．4．1　BeanShell PreProcessor　106
#### 6．4．2　JSR223 PreProcessor　107
#### 6．4．3　BSF PreProcessor　108
#### 6．4．4　Regular User Parameter　108
#### 6．4．5　用户参数　110
#### 6．4．6　JDBC PreProcessor　110
#### 6．4．7　HTML链接解析器　111
#### 6．4．8　HTTP URL 重写修饰符　114
### 6．5　后置处理器　115
#### 6．5．1　Debug PostProcessor　115
#### 6．5．2　JDBC PostProcessor　116
#### 6．5．3　Result Status Action Handler　116
#### 6．5．4　XPath Extractor　117
### 6．6　断言　118
#### 6．6．1　BeanShell Assertion　118
#### 6．6．2　Compare Assertion　120
#### 6．6．3　HTML Assertion　120
#### 6．6．4　Size Assertion　121
#### 6．6．5　XML Schema Assertion　122
#### 6．6．6　XML Assertion　123
#### 6．6．7　XPath Assertion　123
#### 6．6．8　Duration Assertion　124
#### 6．6．9　其他断言元件　124
### 6．7　监听器　124
#### 6．7．1　监听器默认配置　124
#### 6．7．2　Aggregate Graph　127
#### 6．7．3　BeanShell Listener（BeanShell监听器）　130
#### 6．7．4　Distribution Graph（分布图）　130
#### 6．7．5　Response Time Graph（响应时间图形监听器）　131
#### 6．7．6　Simple Data Writer　131
#### 6．7．7　Spline Visualizer（样条线显示取样器）　132
#### 6．7．8　Summary Report（表格形式显示）　133
#### 6．7．9　Save Response to a file（存储服务器响应）　133
#### 6．7．10　View Results Tree（察看结果树）　134
#### 6．7．11　Assertion Results（断言结果）　135
#### 6．7．12　Generate Summary Results（窗口显示结果）　136
#### 6．7．13　View Results in Table（表格形式显示）　136
#### 6．7．14　Monitor Results　137
#### 6．7．15　Aggregate Report　138
#### 6．7．16　Mailer Visualizer　138
### 6．8　函数助手　139
#### 6．8．1　__BeanShell脚本语言　139
#### 6．8．2　__char　140
#### 6．8．3　__counter　141
#### 6．8．4　__CSVRead　142
#### 6．8．5　__escapeHtml　143
#### 6．8．6　__escapeOroRegexChars　143
#### 6．8．7　__eval　144
#### 6．8．8　__evalVar　144
#### 6．8．9　__FileToString　145
#### 6．8．10　__intSum　146
#### 6．8．11　__longSum　146
#### 6．8．12　__javaScript　146
#### 6．8．13　__jexl　146
#### 6．8．14　__log　147
#### 6．8．15　__logn　148
#### 6．8．16　__machineIP　148
#### 6．8．17　__machineName　149
#### 6．8．18　__P　149
#### 6．8．19　__property　149
#### 6．8．20　__Random　150
#### 6．8．21　__RandomString　150
#### 6．8．22　__regexFunction　151
#### 6．8．23　__samplerName　151
#### 6．8．24　__setProperty　152
#### 6．8．25　__split　152
#### 6．8．26　__StringFromFile　153
#### 6．8．27　__TestPlanName　154
#### 6．8．28　__threadNum　154
#### 6．8．29　__time　154
#### 6．8．30　__unescape　155
#### 6．8．31　__unescapeHtml　155
#### 6．8．32　__urldecode　155
#### 6．8．33　__urlencode　155
#### 6．8．34　__UUID　155
#### 6．8．35　__V　155
#### 6．8．36　__XPath　156
### 6．9　本章小结　156
## 第7章　JMeter常用脚本开发　158
### 7．1　BeanShell Sampler　159
### 7．2　Debug Sampler　162
### 7．3　FTP请求　163
### 7．4　Java请求　164
### 7．5　JDBC请求　171
#### 7．5．1　JDBC连接池设置　172
#### 7．5．2　添加JDBC Request　174
### 7．6　JUnit Request　179
#### 7．6．1　JUnit简介　179
#### 7．6．2　JUnit参数　180
#### 7．6．3　JMeter JUnit Request　181
### 7．7　SOAP/XML-RPC Request　182
### 7．8　本章小结　184
## 第8章　JMeter开源测试组件　185
### 8．1　线程组　187
#### 8．1．1　Ultimate Thread Group　187
#### 8．1．2　Stepping Thread Group　188
### 8．2　逻辑控制器　189
### 8．3　配置元件　190
### 8．4　定时器　190
### 8．5　监听器　191
#### 8．5．1　Transactions per Second　191
#### 8．5．2　Response Times Over Time　192
#### 8．5．3　Response Times vs Threads　192
#### 8．5．4　Graphs Generator　192
### 8．6　服务器监控　193
### 8．7　本章小结　195
## 实战篇
## 第9章　性能监控诊断　196
### 9．1　操作系统性能分析介绍　197
### 9．2　系统性能分析思路　198
#### 9．2．1　系统性能分析因素-CPU　199
#### 9．2．2　系统性能分析因素-内存　199
#### 9．2．3　系统性能分析因素-网络　200
#### 9．2．4　系统性能分析因素-I/O　201
#### 9．2．5　系统性能分析因素-总结　201
### 9．3　瓶颈阈值分析思维导图与手册　202
#### 9．3．1　CPU定位分析　202
#### 9．3．2　内存定位分析　203
#### 9．3．3　网络定位分析　203
#### 9．3．4　IO定位分析　204
### 9．4　Linux系统性能分析思路和实践　204
#### 9．4．1　系统负载监控分析实践　205
#### 9．4．2　系统监控分析实践　206
### 9．5　Windows系统性能分析思路和实践　217
#### 9．5．1　性能监视器综述　217
#### 9．5．2　性能监视器工具介绍　218
#### 9．5．3　系统监控分析实践　218
#### 9．5．4　资源监视器介绍和实践　226
### 9．6　Tomcat监控之Probe　235
### 9．7　MySQL监控之MONyog　238
### 9．8　JVM监控　241
#### 9．8．1　jps　241
#### 9．8．2　jstat　243
#### 9．8．3　jmap　245
#### 9．8．4　JVisualVM　247
### 9．9　本章小结　250
## 第10章　性能分析调优　251
### 10．1　性能分析方法　253
### 10．2　单机性能分析与调优　254
#### 10．2．1　性能分析流程　254
#### 10．2．2　系统性能关注点　256
#### 10．2．3　程序优化　261
#### 10．2．4　配置优化　263
#### 10．2．5　数据库连接池优化　263
#### 10．2．6　线程优化　265
#### 10．2．7　DB优化　268
### 10．3　业务流程优化　269
### 10．4　结构优化　269
#### 10．4．1　单机结构　269
#### 10．4．2　集群结构　270
#### 10．4．3　分布式结构　271
### 10．5　本章小结　277
## 第11章　综合实践之诊断分析与调优　278
### 11．1　需求分析　280
#### 11．1．1　需求采集　282
#### 11．1．2　需求分析　285
#### 11．1．3　并发数计算　289
### 11．2　测试模型　291
### 11．3　测试计划　291
### 11．4　环境搭建　292
### 11．5　脚本开发　295
#### 11．5．1　浏览帖子　295
#### 11．5．2　回复帖子　298
#### 11．5．3　发帖　301
### 11．6　数据准备　301
#### 11．6．1　主数据准备　302
#### 11．6．2　数据制作方法　303
### 11．7　场景设计　307
#### 11．7．1　场景设计　307
#### 11．7．2　场景实现　309
### 11．8　测试监控　312
### 11．9　测试执行　313
#### 11．9．1　基准测试　313
#### 11．9．2　配置测试　315
#### 11．9．3　负载测试　319
#### 11．9．4　稳定性测试　327
### 11．10　结果分析　328
### 11．11　测试报告　329
### 11．12　本章小结　330
## 提升篇
## 第12章　互联网测试必备知识——HTTP协议　331
### 12．1　HTTP协议简介　332
### 12．2　HTTP工作原理　332
### 12．3　HTTP请求　333
### 12．4　HTTP应答　335
### 12．5　HTTP捕获　336
### 12．6　Http Watch　337
### 12．6．1　HttpWatch录制　337
### 12．6．2　HttpWatch数据分析　338
### 12．7　本章小结　341
## 第13章　端到端性能监控平台　342
### 13．1　为什么构建基于云的端到端性能监控平台　343
### 13．2　端到端监控的意义　343
### 13．3　前端监控常见策略　343
### 13．4　基于httpWatch的自动捕获　344
### 13．5　基于firebug的自动捕获　345
#### 13．5．1　自动导出瀑布图　345
#### 13．5．2　HARViewer部署　346
#### 13．5．3　基于Fiddler的自动捕获　348
#### 13．5．4　基于YSlow的前端评估体系　348
#### 13．5．5　基于PageSpeed的前端评估体系　350
#### 13．5．6　基于dynaTrace Ajax的前端评估体系　351
### 13．6　构建基于Showslow的监控体系　356
#### 13．6．1　Showslow介绍　356
#### 13．6．2　Showslow环境搭建　356
#### 13．6．3　ShowSlow配置　357
#### 13．6．4　YSlow配置　357
#### 13．6．5　WebDriver驱动的定时监控体系　359
### 13．7　本章小结　361
## 第14章　性能测试自动化——Jenkins+Ant+　JMeter　362
### 14．1　为什么要做性能测试自动化　363
### 14．2　如何做性能测试自动化　365
### 14．3　Ant+JMeter集成　365
#### 14．3．1　Ant下载　366
#### 14．3．2　Ant安装　366
#### 14．3．3　JMeter中配置XML文件来定义测试活动　367
#### 14．3．4　运行测试计划　369
### 14．4　Jenkins+Ant集成　371
#### 14．4．1　Jenkins安装　372
#### 14．4．2　建立Slave节点　374
#### 14．4．3　JMeter任务配置　377
### 14．5　如何运行复杂场景　385
### 14．6　报告自动化　385
#### 14．6．1　配置TPS、响应时间等图表　385
#### 14．6．2　报告合成　386
### 14．7　JMeter脚本拷贝自动化　391
### 14．8　JMeter Agent自动化　395
### 14．9　本章小结　398
## 第15章　JMeter常见问题　399
### 15．1　JMeter无法开启　400
### 15．2　JMeter异常关闭　400
### 15．3　JMeter无法产生负载　401
### 15．4　JMeter日志输出控制　401
### 15．5　记录测试结果影响Jmeter效率　402
### 15．6　JMeter可以测试接口吗　402
### 15．7　JMeter可以测试Dubbo接口吗　403
### 15．8　JMeter可以测试RPC接口吗　404
### 15．9　JMeter函数助手中函数不够用怎么办　404
### 15．10　JMeter支持子事务的定义吗　407
### 15．11　JMeter非GUI方式运行时如何传递运行参数　408
### 15．12　运行场景时察看结果树为什么要关闭　409
### 15．13　多个测试计划如何运行　409
### 15．14　如何找导致CPU瓶颈的程序　410
### 15．15　如何找导致内存瓶颈的程序　410
### 15．16　如何找导致IO瓶颈的程序　411
### 15．17　如何计算并发用户数　411
### 15．18　JMeter可以做哪些测试　412
### 15．19　性能测试的分析方法有哪些　412
### 15．20　如何看懂Java线程栈信息　413
### 15．21　能用本地负载环境测试“云环境”的性能吗　413
### 15．22　性能测试环境和生产环境不一致　414
### 15．23　本章小结　414
## 附录A　Jforum性能测试计划　415
### A．1　性能测试背景　416
### A．2　性能测试目标　416
### A．3　性能测试范围　416
### A．4　名词术语约定　416
### A．5　测试环境　417
#### A．5．1　生产环境系统架构　417
#### A．5．2　测试环境系统架构　418
#### A．5．3　生产环境软硬件配置　418
#### A．5．4　测试环境软硬件配置　419
#### A．5．5　负载机软硬件配置　419
### A．6　需求分析　420
#### A．6．1　业务模型　420
#### A．6．2　性能指标　421
### A．7　测试策略　422
#### A．7．1　测试执行策略　422
#### A．7．2　测试监控策略　422
### A．8　测试场景　423
### A．9　测试准备　423
#### A．9．1　测试工具准备　424
#### A．9．2　测试脚本及程序准备　424
#### A．9．3　测试数据准备　424
#### A．9．4　测试环境准备　424
### A．10　测试组织架构　425
### A．11　交付清单　425
### A．12　项目风险　426
### A．13　附录　426
## 附录B　性能测试报告　427
### B．1　性能测试背景　428
### B．2　性能测试目标　428
### B．3　性能测试范围　428
### B．4　名词术语约定　429
### B．5　测试环境　430
#### B．5．1　生产环境系统架构　430
#### B．5．2　测试环境系统架构　430
#### B．5．3　生产环境软硬件配置　431
#### B．5．4　测试环境软硬件配置　431
#### B．5．5　负载机软硬件配置　431
### B．6　测试数据　432
#### B．6．1　历史数据量　432
#### B．6．2　主数据　432
#### B．6．3　性能指标　432
### B．7　测试进度　433
### B．8　测试结果　433
#### B．8．1　基准测试结果　433
#### B．8．2　配置测试　434
#### B．8．3　负载测试结果　438
#### B．8．4　稳定性测试结果　445
### B．9　测试结论　447
#### B．9．1　测试结论　447
#### B．9．2　系统缺陷　448
### B．10　系统风险　448
## 参考资料　449
